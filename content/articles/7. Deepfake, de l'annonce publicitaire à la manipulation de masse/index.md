---
title: "Deepfake, de l'annonce publicitaire à la manipulation de masse"
date: 2020-06-14
author: Louis Chemineau
videos: [/deepfake_macron.mp4]
tags:
  - Deepfake
  - Manipulation de masse
  - Publicité ciblée
  - Propagande
  - Numérique
  - Macron
  - Trump
  - Politique
  - Solution
---

Certaines personnes refusent l'utilisation des plateformes proposées par les géants du numériques. L'une [des problématiques évoquées]({{< ref "../1. Les deux problèmes des géants du numérique/index.md" >}}) est l'affichage constant de publicités. La problématique ne réside pas que dans la "pollution" du fil d'actualité, ni dans la consommation plus importante de la part des utilisateurs, mais plutôt dans la possibilité de sponsoriser certains contenus pour qu'ils soient affichés à certaines personnes. Donnant ainsi le pouvoir de les pousser à réaliser une action, autrement dit, de les manipuler. Cette action peut être à but commercial avec la publicité ciblée, ou de manière plus problématique, politique avec la propagande, elle aussi ciblée. Dernièrement, un nouvel outil pouvant aider ce genre de pratiques est apparu, les deepfakes.

## Les deepfakes

Les deepfakes sont un nouveau genre de montage vidéo. Aidé par une technique d'intelligence artificielle, le deep learning, il est possible d'animer la photographie d'une personne et de lui faire tenir des propos choisis.

C'est grâce à cela que cette vidéo du président évoquant FLAP a été réalisée.

{{< video src="deepfake_macron.mp4" type="video/mp4" >}}

Bien que de qualité moyenne, cette vidéo montre qu'il est facile de créer des montages permettant de propager de fausses informations. On peut alors imaginer des trucages, bien plus réalistes tel que celui de l'association Solidarité SIDA, présentant Trump annonçant l'éradication du SIDA.

{{< youtube 8dKux8-ZmCI >}}

## Solutions et alternatives

En voyant ces résultats, et leur facilité de création, on peut facilement imaginer cette pratique se généraliser.

Faudrait-il imposer aux grandes plateformes de supprimer tout montage visant à tromper, qu'il soit sponsorisé ou non ? La réponse est non, car il est de plus en plus difficile de détecter les contenus réels des montages, et donc de les retirer. [De la même manière que pour la loi Avia]({{< ref "../5. Peertube, fédérer pour mieux s'exprimer/index.md" >}}), cela risquerait de pousser les grandes plateformes à censurer hâtivement, et donc de faire des erreurs.

Faudrait-il alors leur imposer d'interdire tous contenus sponsorisés politiques, [comme Twitter l'a déjà fait](https://www.lesechos.fr/tech-medias/medias/publicite-politique-sur-twitter-et-facebook-quen-est-il-en-france-1145237) ? Là aussi, le résultat ne serait pas assez efficace. En effet, les montages ont souvent pour but de créer des contenus suscitant de nombreuses réactions, autrement dit, sensationnalistes. Couplé aux algorithmes des plateformes, qui encouragent les utilisateurs à toujours plus d'engagement via l'affichage de contenus sensationnalistes, on imagine facilement qu'un montage obtiendra rapidement le qualificatif de "contenu viral". Il se propagera alors, malgré l'interdiction de publications sponsorisées et politiques. Les grandes plateformes, dont le modèle économique est basé sur l'affichage de publicités ciblées, et qui doivent donc afficher du contenu engageant à l'utilisateur, ne sont pas capables de limiter la propagation de fausses informations, et ne le seront jamais.

Mais tout n'est pas perdu, il existe en effet certaines plateformes dont le modèle économique ne dépend pas de l'affichage de publicité ciblées. Basées sur des logiciels tel que Peertube ou Mastodon, leurs modèles économiques sont multiples. Par exemple, certaines se financent en faisant payer leurs utilisateurs. La publicité est donc absente des ces plateformes, et les contenus affichés moins sensationnalistes.

Afin de limiter la propagation de fausses informations, l'une des solutions est de ne plus financer les grands réseaux sociaux au travers de notre consommation, mais de financer directement les plateformes que l'on utilise.

{{< about >}}
